{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_filepath):\n",
    "    '''\n",
    "    Reads in the table from the sqlite database as a dataframe and returns feature and response as two different dataframes\n",
    "    \n",
    "    Arguments:\n",
    "        database_filepath -> path of the sqlite database\n",
    "    \n",
    "    Output:\n",
    "        X -> dataframe containg the features\n",
    "        y -> dataframe containg the response\n",
    "        category_names -> list of the response columns\n",
    "    '''\n",
    "    engine = create_engine(f'sqlite:///{database_filepath}')\n",
    "    df = pd.read_sql(database_filepath.split('/')[-1].replace(\".db\",\"\"), con = engine)\n",
    "    \n",
    "    X = df.iloc[:,1]\n",
    "    y = df.iloc[:,4:]\n",
    "    category_names = y.columns\n",
    "    \n",
    "    return X,y,category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Normalize, remove punctuation, tokenize the words, remove stop words and lemmatize\n",
    "    \n",
    "    Arguments:\n",
    "        text -> \n",
    "        \n",
    "    Output:\n",
    "        lemmed -> transformed text\n",
    "    '''\n",
    "    # Normalize the text\n",
    "    clean_text = text.lower()\n",
    "    # Remove punctuation\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", clean_text)\n",
    "    # Tokenize the sentence\n",
    "    words = word_tokenize(clean_text)\n",
    "    # remove stop words\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    # lemmatize or stem the words\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w).strip() for w in words]\n",
    "    \n",
    "    return lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    '''\n",
    "    Instanciate the model\n",
    "    \n",
    "    Output:\n",
    "        cv -> cross validation model\n",
    "    '''\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # hyperparameters for the Random forrest classifier \n",
    "    parameters = {\n",
    "        \"clf__estimator__n_estimators\": [10, 50, 100],\n",
    "        \"clf__estimator__max_depth\": [3, 8]\n",
    "    }\n",
    "    \n",
    "    # run cross validation\n",
    "    cv = GridSearchCV(pipeline, param_grid = parameters, cv = 5)\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,category_name = load_data('../data/DisasterResponse.db')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7fd37ad1af70>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={'clf__estimator__max_depth': [3, 8],\n",
       "                         'clf__estimator__n_estimators': [10, 50, 100]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7fd37ad1af70>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(max_depth=3,\n",
       "                                                                        n_estimators=50)))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.98      0.94     10847\\n           1       0.84      0.48      0.61      2261\\n\\n    accuracy                           0.89     13108\\n   macro avg       0.87      0.73      0.77     13108\\nweighted avg       0.89      0.89      0.88     13108\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "classification_report(y_true = Y_test.values[:,1], y_pred = y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9001185034704587,\n",
       "  'recall': 0.9803632340739374,\n",
       "  'f1-score': 0.9385287498345174,\n",
       "  'support': 10847},\n",
       " '1': {'precision': 0.8353941267387944,\n",
       "  'recall': 0.47810703228659884,\n",
       "  'f1-score': 0.6081575246132208,\n",
       "  'support': 2261},\n",
       " 'accuracy': 0.8937290204455295,\n",
       " 'macro avg': {'precision': 0.8677563151046266,\n",
       "  'recall': 0.7292351331802681,\n",
       "  'f1-score': 0.773343137223869,\n",
       "  'support': 13108},\n",
       " 'weighted avg': {'precision': 0.8889541903952152,\n",
       "  'recall': 0.8937290204455295,\n",
       "  'f1-score': 0.8815429899760072,\n",
       "  'support': 13108}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_true = Y_test.values[:,1], y_pred = y_pred[:,1], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = classification_report(y_true = Y_test.values[:,1], y_pred = y_pred[:,1], output_dict=True)['weighted avg']['f1-score']\n",
    "precision = classification_report(y_true = Y_test.values[:,1], y_pred = y_pred[:,1], output_dict=True)['weighted avg']['precision']\n",
    "recall = classification_report(y_true = Y_test.values[:,1], y_pred = y_pred[:,1], output_dict=True)['weighted avg']['recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    best_model = model.best_estimator_\n",
    "    Y_pred = best_model.predict(X_test)\n",
    "    for i in range(Y_test.shape[1]):\n",
    "        clf_result = classification_report(y_true = Y_test.values[:,i], y_pred = Y_pred[:,i], output_dict=True)['weighted avg']\n",
    "        f1_score = clf_result['f1-score']\n",
    "        precision = clf_result['precision']\n",
    "        recall = clf_result['recall']\n",
    "        print(f\"For the column {category_names[i]}, f1_score is {f1_score} ,precison is {precision}, recall is {recall}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the column related, f1_score is 0.6560454262548845 ,precison is 0.5772428992760689, recall is 0.7597650289899298\n",
      "For the column request, f1_score is 0.7533628084552239 ,precison is 0.6894522619948785, recall is 0.8303326212999694\n",
      "For the column offer, f1_score is 0.9932534742527778 ,precison is 0.9910181235134996, recall is 0.9954989319499542\n",
      "For the column aid_related, f1_score is 0.4350794307617319 ,precison is 0.7316757923654328, recall is 0.5855965822398536\n",
      "For the column medical_help, f1_score is 0.880292622117604 ,precison is 0.8446658876017823, recall is 0.9190570643881599\n",
      "For the column medical_products, f1_score is 0.9275981779142335 ,precison is 0.905023885973843, recall is 0.9513274336283186\n",
      "For the column search_and_rescue, f1_score is 0.9595618388804907 ,precison is 0.9465680773301942, recall is 0.9729173024107415\n",
      "For the column security, f1_score is 0.9748955532841066 ,precison is 0.9667144035388173, recall is 0.9832163564235581\n",
      "For the column military, f1_score is 0.9516327209354197 ,precison is 0.9362053519089643, recall is 0.9675770521818736\n",
      "For the column child_alone, f1_score is 1.0 ,precison is 1.0, recall is 1.0\n",
      "For the column water, f1_score is 0.9073979836366655 ,precison is 0.8790850621148927, recall is 0.9375953616112298\n",
      "For the column food, f1_score is 0.8318215649954369 ,precison is 0.7842272581792501, recall is 0.88556606652426\n",
      "For the column shelter, f1_score is 0.8668679073725526 ,precison is 0.8277834602214099, recall is 0.9098260604211169\n",
      "For the column clothing, f1_score is 0.9759197443133897 ,precison is 0.9680650347448008, recall is 0.9839029600244126\n",
      "For the column money, f1_score is 0.9668243204073628 ,precison is 0.956092481940833, recall is 0.9777998169057064\n",
      "For the column missing_people, f1_score is 0.9833238344828522 ,precison is 0.9778475879221834, recall is 0.9888617638083613\n",
      "For the column refugees, f1_score is 0.9475607125594355 ,precison is 0.9308981595959819, recall is 0.9648306377784559\n",
      "For the column death, f1_score is 0.9322136062451647 ,precison is 0.910984909154519, recall is 0.9544552944766554\n",
      "For the column other_aid, f1_score is 0.8081070748741613 ,precison is 0.7551806235635521, recall is 0.8690112908147696\n",
      "For the column infrastructure_related, f1_score is 0.9012462833542955 ,precison is 0.87123453459902, recall is 0.9333994507171193\n",
      "For the column transport, f1_score is 0.9297363816272478 ,precison is 0.9077838785670073, recall is 0.9527769301190113\n",
      "For the column buildings, f1_score is 0.9254611053093297 ,precison is 0.9022680954608315, recall is 0.9498779371376259\n",
      "For the column electricity, f1_score is 0.9720518474122101 ,precison is 0.9629675972361347, recall is 0.9813091241989624\n",
      "For the column tools, f1_score is 0.9913114496505868 ,precison is 0.988437644715683, recall is 0.9942020140372292\n",
      "For the column hospitals, f1_score is 0.9832098304688058 ,precison is 0.9776967146205104, recall is 0.9887854745193775\n",
      "For the column shops, f1_score is 0.993482003432846 ,precison is 0.9913219304165326, recall is 0.9956515105279219\n",
      "For the column aid_centers, f1_score is 0.9816140851782577 ,precison is 0.9755857106087694, recall is 0.9877174244736039\n",
      "For the column other_infrastructure, f1_score is 0.9327768224613195 ,precison is 0.911713201813734, recall is 0.9548367409215746\n",
      "For the column weather_related, f1_score is 0.604689095835741 ,precison is 0.7989922817079729, recall is 0.7213152273420812\n",
      "For the column floods, f1_score is 0.8777370831415071 ,precison is 0.8414437127522261, recall is 0.9173024107415318\n",
      "For the column storm, f1_score is 0.8641002818478787 ,precison is 0.8243165985937442, recall is 0.9079188281965213\n",
      "For the column fire, f1_score is 0.9834378414560918 ,precison is 0.9779984728639675, recall is 0.9889380530973452\n",
      "For the column earthquake, f1_score is 0.8591238395801398 ,precison is 0.8180945808391291, recall is 0.904485810192249\n",
      "For the column cold, f1_score is 0.9708012091558432 ,precison is 0.9613213072049773, recall is 0.9804699420201404\n",
      "For the column other_weather, f1_score is 0.9241119591706964 ,precison is 0.9005297612501442, recall is 0.94896246566982\n",
      "For the column direct_report, f1_score is 0.7223785425013903 ,precison is 0.6530780376802506, recall is 0.8081324382056759\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, Y_test, category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model.best_estimator_, open('test_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickled_model = pickle.load(open('test_model.pkl', 'rb'))\n",
    "pickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
